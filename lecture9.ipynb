{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Essential pandas functionality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Function application and mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(-np.arange(12).reshape((4,3)), columns=list('bde'),\n",
    "                     index=['Utah', 'Ohio', 'Texas', 'Oregon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a Numpy *ufunc*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        b   d   e\n",
       "Utah    0   1   2\n",
       "Ohio    3   4   5\n",
       "Texas   6   7   8\n",
       "Oregon  9  10  11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Write a lambda function and apply it with `frame.apply(f)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         b  d  e\n",
       "Utah    10  9  8\n",
       "Ohio     7  6  5\n",
       "Texas    4  3  2\n",
       "Oregon   1  0 -1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f = lambda x: x[0]+10\n",
    "frame.apply(lambda x: x+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### =pd.applymap=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-3.00</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-6.00</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>-9.00</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-11.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b       d       e\n",
       "Utah     0.00   -1.00   -2.00\n",
       "Ohio    -3.00   -4.00   -5.00\n",
       "Texas   -6.00   -7.00   -8.00\n",
       "Oregon  -9.00  -10.00  -11.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format = lambda x: '%.2f' % x\n",
    "frame.applymap(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sorting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    0\n",
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series(range(4), index=['d', 'a', 'b', 'c'])\n",
    "obj\n",
    "obj.sort_index()\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sorting DataFrames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  a\n",
       "0  4  0\n",
       "1  7  1\n",
       "2 -3  0\n",
       "3  2  1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  a\n",
       "2 -3  0\n",
       "3  2  1\n",
       "0  4  0\n",
       "1  7  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.sort_values(by='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   b  a\n",
      "0  4  0\n",
      "1  7  1\n",
      "2 -3  0\n",
      "3  2  1\n",
      "   b  a\n",
      "2 -3  0\n",
      "3  2  1\n",
      "0  4  0\n",
      "1  7  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  a\n",
       "2 -3  0\n",
       "0  4  0\n",
       "3  2  1\n",
       "1  7  1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(frame)\n",
    "print(frame.sort_values(by='b'))\n",
    "frame.sort_values(by=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of common mathematical and statistical methods are available for Series and DataFrames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                   [np.nan, np.nan], [0.75, -1.3]],\n",
    "                  index=['a', 'b', 'c', 'd'],\n",
    "                  columns=['one', 'two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one    3.083333\n",
       "two   -2.900000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      NaN\n",
       "b    1.300\n",
       "c      NaN\n",
       "d   -0.275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(axis='columns', skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.083333</td>\n",
       "      <td>-2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.493685</td>\n",
       "      <td>2.262742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.075000</td>\n",
       "      <td>-3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.400000</td>\n",
       "      <td>-2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>-2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>-1.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            one       two\n",
       "count  3.000000  2.000000\n",
       "mean   3.083333 -2.900000\n",
       "std    3.493685  2.262742\n",
       "min    0.750000 -4.500000\n",
       "25%    1.075000 -3.700000\n",
       "50%    1.400000 -2.900000\n",
       "75%    4.250000 -2.100000\n",
       "max    7.100000 -1.300000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descriptive and summary statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/pdsummary.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab some data of stock prices and volumes from Yahoo! finance\n",
    "\n",
    "    conda install pandas-datareader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL':                   High         Low        Open       Close       Volume  \\\n",
       " Date                                                                      \n",
       " 2010-01-04   30.642857   30.340000   30.490000   30.572857  123432400.0   \n",
       " 2010-01-05   30.798571   30.464285   30.657143   30.625713  150476200.0   \n",
       " 2010-01-06   30.747143   30.107143   30.625713   30.138571  138040000.0   \n",
       " 2010-01-07   30.285715   29.864286   30.250000   30.082857  119282800.0   \n",
       " 2010-01-08   30.285715   29.865715   30.042856   30.282858  111902700.0   \n",
       " 2010-01-11   30.428572   29.778572   30.400000   30.015715  115557400.0   \n",
       " 2010-01-12   29.967142   29.488571   29.884285   29.674286  148614900.0   \n",
       " 2010-01-13   30.132856   29.157143   29.695715   30.092857  151473000.0   \n",
       " 2010-01-14   30.065714   29.860001   30.015715   29.918571  108223500.0   \n",
       " 2010-01-15   30.228571   29.410000   30.132856   29.418571  148516900.0   \n",
       " 2010-01-19   30.741428   29.605715   29.761429   30.719999  182501900.0   \n",
       " 2010-01-20   30.792856   29.928572   30.701429   30.247143  153038200.0   \n",
       " 2010-01-21   30.472857   29.601429   30.297142   29.724285  152038600.0   \n",
       " 2010-01-22   29.642857   28.165714   29.540001   28.250000  220441900.0   \n",
       " 2010-01-25   29.242857   28.598572   28.930000   29.010000  266424900.0   \n",
       " 2010-01-26   30.530001   28.940001   29.421429   29.420000  466777500.0   \n",
       " 2010-01-27   30.082857   28.504286   29.549999   29.697144  430642100.0   \n",
       " 2010-01-28   29.357143   28.385714   29.275715   28.469999  293375600.0   \n",
       " 2010-01-29   28.885714   27.178572   28.725714   27.437143  311488100.0   \n",
       " 2010-02-01   28.000000   27.328571   27.481428   27.818571  187469100.0   \n",
       " 2010-02-02   28.045713   27.625713   27.987143   27.980000  174585600.0   \n",
       " 2010-02-03   28.600000   27.774286   27.881428   28.461428  153832000.0   \n",
       " 2010-02-04   28.338572   27.367144   28.104286   27.435715  189413000.0   \n",
       " 2010-02-05   28.000000   27.264286   27.518572   27.922857  212576700.0   \n",
       " 2010-02-08   28.268572   27.714285   27.955715   27.731428  119567700.0   \n",
       " 2010-02-09   28.214285   27.821428   28.059999   28.027143  158221700.0   \n",
       " 2010-02-10   28.085714   27.751429   27.984285   27.874287   92590400.0   \n",
       " 2010-02-11   28.535715   27.722857   27.840000   28.381428  137586400.0   \n",
       " 2010-02-12   28.805714   27.928572   28.301428   28.625713  163867200.0   \n",
       " 2010-02-16   29.098572   28.788572   28.848572   29.057142  135934400.0   \n",
       " ...                ...         ...         ...         ...          ...   \n",
       " 2019-01-08  151.820007  148.520004  149.559998  150.750000   41025300.0   \n",
       " 2019-01-09  154.529999  149.630005  151.289993  153.309998   45099100.0   \n",
       " 2019-01-10  153.970001  150.860001  152.500000  153.800003   35780700.0   \n",
       " 2019-01-11  153.699997  151.509995  152.880005  152.289993   27023200.0   \n",
       " 2019-01-14  151.270004  149.220001  150.850006  150.000000   32439200.0   \n",
       " 2019-01-15  153.389999  150.050003  150.270004  153.070007   28710900.0   \n",
       " 2019-01-16  155.880005  153.000000  153.080002  154.940002   30569700.0   \n",
       " 2019-01-17  157.660004  153.259995  154.199997  155.860001   29821200.0   \n",
       " 2019-01-18  157.880005  155.979996  157.500000  156.820007   33751000.0   \n",
       " 2019-01-22  156.729996  152.619995  156.410004  153.300003   30394000.0   \n",
       " 2019-01-23  155.139999  151.699997  154.149994  153.919998   23130600.0   \n",
       " 2019-01-24  154.479996  151.740005  154.110001  152.699997   25441500.0   \n",
       " 2019-01-25  158.130005  154.320007  155.479996  157.759995   33535500.0   \n",
       " 2019-01-28  156.330002  153.660004  155.789993  156.300003   26192100.0   \n",
       " 2019-01-29  158.130005  154.110001  156.250000  154.679993   41587200.0   \n",
       " 2019-01-30  166.149994  160.229996  163.250000  165.250000   61109800.0   \n",
       " 2019-01-31  169.000000  164.559998  166.110001  166.440002   40739600.0   \n",
       " 2019-02-01  168.979996  165.929993  166.960007  166.520004   32668100.0   \n",
       " 2019-02-04  171.660004  167.279999  167.410004  171.250000   31495500.0   \n",
       " 2019-02-05  175.080002  172.350006  172.860001  174.179993   36101600.0   \n",
       " 2019-02-06  175.570007  172.850006  174.649994  174.240005   28239600.0   \n",
       " 2019-02-07  173.940002  170.339996  172.399994  170.940002   31741700.0   \n",
       " 2019-02-08  170.660004  168.419998  168.990005  170.410004   23820000.0   \n",
       " 2019-02-11  171.210007  169.250000  171.050003  169.429993   20993400.0   \n",
       " 2019-02-12  171.000000  169.699997  170.100006  170.889999   22283500.0   \n",
       " 2019-02-13  172.479996  169.919998  171.389999  170.179993   22490200.0   \n",
       " 2019-02-14  171.259995  169.380005  169.710007  170.800003   21835700.0   \n",
       " 2019-02-15  171.699997  169.750000  171.250000  170.419998   24626800.0   \n",
       " 2019-02-19  171.440002  169.490005  169.710007  170.929993   18962100.0   \n",
       " 2019-02-20  173.320007  171.000000  171.190002  172.029999       3903.0   \n",
       " \n",
       "              Adj Close  \n",
       " Date                    \n",
       " 2010-01-04   20.386072  \n",
       " 2010-01-05   20.421322  \n",
       " 2010-01-06   20.096491  \n",
       " 2010-01-07   20.059338  \n",
       " 2010-01-08   20.192701  \n",
       " 2010-01-11   20.014568  \n",
       " 2010-01-12   19.786903  \n",
       " 2010-01-13   20.066006  \n",
       " 2010-01-14   19.949797  \n",
       " 2010-01-15   19.616390  \n",
       " 2010-01-19   20.484186  \n",
       " 2010-01-20   20.168890  \n",
       " 2010-01-21   19.820242  \n",
       " 2010-01-22   18.837185  \n",
       " 2010-01-25   19.343958  \n",
       " 2010-01-26   19.617346  \n",
       " 2010-01-27   19.802147  \n",
       " 2010-01-28   18.983883  \n",
       " 2010-01-29   18.295170  \n",
       " 2010-02-01   18.549507  \n",
       " 2010-02-02   18.657150  \n",
       " 2010-02-03   18.978167  \n",
       " 2010-02-04   18.294220  \n",
       " 2010-02-05   18.619045  \n",
       " 2010-02-08   18.491404  \n",
       " 2010-02-09   18.688580  \n",
       " 2010-02-10   18.586657  \n",
       " 2010-02-11   18.924822  \n",
       " 2010-02-12   19.087709  \n",
       " 2010-02-16   19.375387  \n",
       " ...                ...  \n",
       " 2019-01-08  150.106216  \n",
       " 2019-01-09  152.655289  \n",
       " 2019-01-10  153.143204  \n",
       " 2019-01-11  151.639633  \n",
       " 2019-01-14  149.359421  \n",
       " 2019-01-15  152.416321  \n",
       " 2019-01-16  154.278336  \n",
       " 2019-01-17  155.194397  \n",
       " 2019-01-18  156.150314  \n",
       " 2019-01-22  152.645340  \n",
       " 2019-01-23  153.262680  \n",
       " 2019-01-24  152.047897  \n",
       " 2019-01-25  157.086288  \n",
       " 2019-01-28  155.632523  \n",
       " 2019-01-29  154.019440  \n",
       " 2019-01-30  164.544296  \n",
       " 2019-01-31  165.729218  \n",
       " 2019-02-01  165.808884  \n",
       " 2019-02-04  170.518677  \n",
       " 2019-02-05  173.436157  \n",
       " 2019-02-06  173.495911  \n",
       " 2019-02-07  170.210007  \n",
       " 2019-02-08  170.410004  \n",
       " 2019-02-11  169.429993  \n",
       " 2019-02-12  170.889999  \n",
       " 2019-02-13  170.179993  \n",
       " 2019-02-14  170.800003  \n",
       " 2019-02-15  170.419998  \n",
       " 2019-02-19  170.929993  \n",
       " 2019-02-20  172.029999  \n",
       " \n",
       " [2298 rows x 6 columns],\n",
       " 'IBM':                   High         Low        Open       Close      Volume  \\\n",
       " Date                                                                     \n",
       " 2010-01-04  132.970001  130.850006  131.179993  132.449997   6155300.0   \n",
       " 2010-01-05  131.850006  130.100006  131.679993  130.850006   6841400.0   \n",
       " 2010-01-06  131.490005  129.809998  130.679993  130.000000   5605300.0   \n",
       " 2010-01-07  130.250000  128.910004  129.869995  129.550003   5840600.0   \n",
       " 2010-01-08  130.919998  129.050003  129.070007  130.850006   4197200.0   \n",
       " 2010-01-11  131.059998  128.669998  131.059998  129.479996   5730400.0   \n",
       " 2010-01-12  131.330002  129.000000  129.029999  130.509995   8081500.0   \n",
       " 2010-01-13  131.119995  129.160004  130.389999  130.229996   6455400.0   \n",
       " 2010-01-14  132.710007  129.910004  130.550003  132.309998   7111800.0   \n",
       " 2010-01-15  132.889999  131.089996  132.029999  131.779999   8494400.0   \n",
       " 2010-01-19  134.250000  131.559998  131.630005  134.139999  13916200.0   \n",
       " 2010-01-20  131.149994  128.949997  130.460007  130.250000  15197500.0   \n",
       " 2010-01-21  130.690002  128.059998  130.470001  129.000000   9608600.0   \n",
       " 2010-01-22  128.889999  125.370003  128.669998  125.500000  10088600.0   \n",
       " 2010-01-25  126.889999  125.709999  126.330002  126.120003   5738500.0   \n",
       " 2010-01-26  127.750000  125.410004  125.919998  125.750000   7135300.0   \n",
       " 2010-01-27  126.959999  125.040001  125.820000  126.330002   8719200.0   \n",
       " 2010-01-28  127.040001  123.050003  127.029999  123.750000   9622200.0   \n",
       " 2010-01-29  125.000000  121.900002  124.320000  122.389999  11571200.0   \n",
       " 2010-02-01  124.949997  122.779999  123.230003  124.669998   7242900.0   \n",
       " 2010-02-02  125.809998  123.949997  124.790001  125.529999   5899900.0   \n",
       " 2010-02-03  126.070000  125.070000  125.160004  125.660004   4177100.0   \n",
       " 2010-02-04  125.440002  122.900002  125.190002  123.000000   9126900.0   \n",
       " 2010-02-05  123.720001  121.830002  123.040001  123.519997   8617000.0   \n",
       " 2010-02-08  123.220001  121.739998  123.150002  121.879997   5718500.0   \n",
       " 2010-02-09  124.199997  122.459999  122.650002  123.209999   6044500.0   \n",
       " 2010-02-10  123.650002  122.209999  122.940002  122.809998   5219100.0   \n",
       " 2010-02-11  124.199997  122.059998  122.580002  123.730003   5089000.0   \n",
       " 2010-02-12  124.050003  121.610001  123.010002  124.000000   8017700.0   \n",
       " 2010-02-16  125.230003  124.110001  124.910004  125.230003   6777300.0   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2019-01-08  120.570000  118.980003  119.660004  119.830002   4763600.0   \n",
       " 2019-01-09  121.400002  119.870003  120.910004  120.690002   3633700.0   \n",
       " 2019-01-10  121.860001  119.949997  120.080002  121.790001   3910000.0   \n",
       " 2019-01-11  121.620003  120.199997  121.580002  121.459999   3722400.0   \n",
       " 2019-01-14  120.650002  119.760002  120.510002  120.389999   5228700.0   \n",
       " 2019-01-15  121.930000  120.820000  120.959999  121.730003   3507500.0   \n",
       " 2019-01-16  122.000000  120.830002  121.580002  121.620003   3841100.0   \n",
       " 2019-01-17  122.410004  120.550003  120.559998  122.190002   5029900.0   \n",
       " 2019-01-18  124.720001  122.709999  123.269997  123.820000   6008500.0   \n",
       " 2019-01-22  123.800003  121.540001  123.300003  122.519997  10052400.0   \n",
       " 2019-01-23  135.000000  130.309998  131.369995  132.889999  22063700.0   \n",
       " 2019-01-24  133.210007  131.429993  132.630005  132.529999   6322900.0   \n",
       " 2019-01-25  134.440002  132.429993  132.869995  133.970001   5707400.0   \n",
       " 2019-01-28  134.809998  132.580002  133.100006  134.270004   5357700.0   \n",
       " 2019-01-29  135.410004  133.600006  134.289993  134.330002   5037100.0   \n",
       " 2019-01-30  135.029999  133.250000  134.000000  134.380005   4500900.0   \n",
       " 2019-01-31  134.720001  133.740005  134.449997  134.419998   4884000.0   \n",
       " 2019-02-01  135.199997  133.350006  134.970001  134.100006   3806000.0   \n",
       " 2019-02-04  135.199997  132.990005  134.020004  135.190002   3966600.0   \n",
       " 2019-02-05  135.820007  134.919998  135.279999  135.550003   5398900.0   \n",
       " 2019-02-06  136.649994  135.169998  135.220001  136.320007   4879700.0   \n",
       " 2019-02-07  134.470001  132.119995  133.550003  133.190002   4379400.0   \n",
       " 2019-02-08  133.710007  132.190002  132.339996  133.710007   3249800.0   \n",
       " 2019-02-11  135.149994  133.910004  134.289993  133.990005   3095100.0   \n",
       " 2019-02-12  136.199997  134.860001  135.149994  136.050003   3317200.0   \n",
       " 2019-02-13  137.919998  136.410004  136.919998  137.520004   4253000.0   \n",
       " 2019-02-14  137.600006  136.210007  137.169998  136.479996   2789400.0   \n",
       " 2019-02-15  138.190002  137.389999  137.580002  138.029999   3844100.0   \n",
       " 2019-02-19  138.699997  137.360001  137.809998  138.699997   3384000.0   \n",
       " 2019-02-20  139.240005  137.220306  138.759995  138.000000   3801979.0   \n",
       " \n",
       "              Adj Close  \n",
       " Date                    \n",
       " 2010-01-04  100.478867  \n",
       " 2010-01-05   99.265091  \n",
       " 2010-01-06   98.620255  \n",
       " 2010-01-07   98.278870  \n",
       " 2010-01-08   99.265091  \n",
       " 2010-01-11   98.225777  \n",
       " 2010-01-12   99.007156  \n",
       " 2010-01-13   98.794746  \n",
       " 2010-01-14  100.372673  \n",
       " 2010-01-15   99.970589  \n",
       " 2010-01-19  101.760918  \n",
       " 2010-01-20   98.809929  \n",
       " 2010-01-21   97.861649  \n",
       " 2010-01-22   95.206505  \n",
       " 2010-01-25   95.676834  \n",
       " 2010-01-26   95.396156  \n",
       " 2010-01-27   95.836143  \n",
       " 2010-01-28   93.878906  \n",
       " 2010-01-29   92.847176  \n",
       " 2010-02-01   94.576828  \n",
       " 2010-02-02   95.229240  \n",
       " 2010-02-03   95.327866  \n",
       " 2010-02-04   93.309929  \n",
       " 2010-02-05   93.704422  \n",
       " 2010-02-08   92.873825  \n",
       " 2010-02-09   93.887291  \n",
       " 2010-02-10   93.582497  \n",
       " 2010-02-11   94.283569  \n",
       " 2010-02-12   94.489265  \n",
       " 2010-02-16   95.426559  \n",
       " ...                ...  \n",
       " 2019-01-08  118.449913  \n",
       " 2019-01-09  119.300011  \n",
       " 2019-01-10  120.387337  \n",
       " 2019-01-11  120.061142  \n",
       " 2019-01-14  119.003464  \n",
       " 2019-01-15  120.328033  \n",
       " 2019-01-16  120.219299  \n",
       " 2019-01-17  120.782738  \n",
       " 2019-01-18  122.393959  \n",
       " 2019-01-22  121.108925  \n",
       " 2019-01-23  131.359497  \n",
       " 2019-01-24  131.003647  \n",
       " 2019-01-25  132.427063  \n",
       " 2019-01-28  132.723618  \n",
       " 2019-01-29  132.782913  \n",
       " 2019-01-30  132.832336  \n",
       " 2019-01-31  132.871872  \n",
       " 2019-02-01  132.555573  \n",
       " 2019-02-04  133.633011  \n",
       " 2019-02-05  133.988861  \n",
       " 2019-02-06  134.750000  \n",
       " 2019-02-07  133.190002  \n",
       " 2019-02-08  133.710007  \n",
       " 2019-02-11  133.990005  \n",
       " 2019-02-12  136.050003  \n",
       " 2019-02-13  137.520004  \n",
       " 2019-02-14  136.479996  \n",
       " 2019-02-15  138.029999  \n",
       " 2019-02-19  138.699997  \n",
       " 2019-02-20  138.000000  \n",
       " \n",
       " [2298 rows x 6 columns],\n",
       " 'MSFT':                   High         Low        Open       Close       Volume  \\\n",
       " Date                                                                      \n",
       " 2010-01-04   31.100000   30.590000   30.620001   30.950001   38409100.0   \n",
       " 2010-01-05   31.100000   30.639999   30.850000   30.959999   49749600.0   \n",
       " 2010-01-06   31.080000   30.520000   30.879999   30.770000   58182400.0   \n",
       " 2010-01-07   30.700001   30.190001   30.629999   30.450001   50559700.0   \n",
       " 2010-01-08   30.879999   30.240000   30.280001   30.660000   51197400.0   \n",
       " 2010-01-11   30.760000   30.120001   30.709999   30.270000   68754700.0   \n",
       " 2010-01-12   30.400000   29.910000   30.150000   30.070000   65912100.0   \n",
       " 2010-01-13   30.520000   30.010000   30.260000   30.350000   51863500.0   \n",
       " 2010-01-14   31.100000   30.260000   30.309999   30.959999   63228100.0   \n",
       " 2010-01-15   31.240000   30.709999   31.080000   30.860001   79913200.0   \n",
       " 2010-01-19   31.240000   30.680000   30.750000   31.100000   46575700.0   \n",
       " 2010-01-20   30.940001   30.309999   30.809999   30.590000   54849500.0   \n",
       " 2010-01-21   30.719999   30.000000   30.610001   30.010000   73086700.0   \n",
       " 2010-01-22   30.200001   28.840000   30.000000   28.959999  102004600.0   \n",
       " 2010-01-25   29.660000   29.100000   29.240000   29.320000   63373000.0   \n",
       " 2010-01-26   29.850000   29.090000   29.200001   29.500000   66639900.0   \n",
       " 2010-01-27   29.820000   29.020000   29.350000   29.670000   63949500.0   \n",
       " 2010-01-28   29.870001   28.889999   29.840000   29.160000  117513700.0   \n",
       " 2010-01-29   29.920000   27.660000   29.900000   28.180000  193888500.0   \n",
       " 2010-02-01   28.480000   27.920000   28.389999   28.410000   85931100.0   \n",
       " 2010-02-02   28.500000   28.139999   28.370001   28.459999   54413700.0   \n",
       " 2010-02-03   28.790001   28.120001   28.260000   28.629999   61397900.0   \n",
       " 2010-02-04   28.500000   27.809999   28.379999   27.840000   77850000.0   \n",
       " 2010-02-05   28.280001   27.570000   28.000000   28.020000   80960100.0   \n",
       " 2010-02-08   28.080000   27.570000   28.010000   27.719999   52820600.0   \n",
       " 2010-02-09   28.340000   27.750000   27.969999   28.010000   59195800.0   \n",
       " 2010-02-10   28.240000   27.840000   28.030001   27.990000   48591300.0   \n",
       " 2010-02-11   28.400000   27.700001   27.930000   28.120001   65993700.0   \n",
       " 2010-02-12   28.059999   27.580000   27.809999   27.930000   81117200.0   \n",
       " 2010-02-16   28.370001   28.020000   28.129999   28.350000   51935600.0   \n",
       " ...                ...         ...         ...         ...          ...   \n",
       " 2019-01-08  103.970001  101.709999  103.040001  102.800003   31514400.0   \n",
       " 2019-01-09  104.879997  103.239998  103.860001  104.269997   32280800.0   \n",
       " 2019-01-10  103.750000  102.379997  103.220001  103.599998   30067600.0   \n",
       " 2019-01-11  103.440002  101.639999  103.190002  102.800003   28314200.0   \n",
       " 2019-01-14  102.870003  101.260002  101.900002  102.050003   28437100.0   \n",
       " 2019-01-15  105.050003  101.879997  102.510002  105.010002   31587600.0   \n",
       " 2019-01-16  106.260002  104.959999  105.260002  105.379997   29853900.0   \n",
       " 2019-01-17  106.629997  104.760002  105.000000  106.120003   28393000.0   \n",
       " 2019-01-18  107.900002  105.910004  107.459999  107.709999   37427600.0   \n",
       " 2019-01-22  107.099998  104.860001  106.750000  105.680000   32371300.0   \n",
       " 2019-01-23  107.040001  105.339996  106.120003  106.709999   25874300.0   \n",
       " 2019-01-24  107.000000  105.339996  106.860001  106.199997   23164800.0   \n",
       " 2019-01-25  107.879997  106.199997  107.239998  107.169998   31225600.0   \n",
       " 2019-01-28  106.480003  104.660004  106.260002  105.080002   29476700.0   \n",
       " 2019-01-29  104.970001  102.169998  104.879997  102.940002   31490500.0   \n",
       " 2019-01-30  106.379997  104.330002  104.620003  106.379997   49471900.0   \n",
       " 2019-01-31  105.220001  103.180000  103.800003  104.430000   55636400.0   \n",
       " 2019-02-01  104.099998  102.349998  103.779999  102.779999   35535700.0   \n",
       " 2019-02-04  105.800003  102.769997  102.870003  105.739998   31315100.0   \n",
       " 2019-02-05  107.269997  105.959999  106.059998  107.220001   27325400.0   \n",
       " 2019-02-06  107.000000  105.529999  107.000000  106.029999   20609800.0   \n",
       " 2019-02-07  105.589996  104.290001  105.190002  105.269997   29760700.0   \n",
       " 2019-02-08  105.779999  104.260002  104.389999  105.669998   21461100.0   \n",
       " 2019-02-11  106.580002  104.970001  106.199997  105.250000   18914100.0   \n",
       " 2019-02-12  107.139999  105.480003  106.139999  106.889999   25056600.0   \n",
       " 2019-02-13  107.779999  106.709999  107.500000  106.809998   18394900.0   \n",
       " 2019-02-14  107.290001  105.660004  106.309998  106.900002   21784700.0   \n",
       " 2019-02-15  108.300003  107.360001  107.910004  108.220001   26606900.0   \n",
       " 2019-02-19  108.660004  107.779999  107.790001  108.169998   18027400.0   \n",
       " 2019-02-20  107.940002  106.294998  107.860001  107.150002       3446.0   \n",
       " \n",
       "              Adj Close  \n",
       " Date                    \n",
       " 2010-01-04   24.615801  \n",
       " 2010-01-05   24.623755  \n",
       " 2010-01-06   24.472631  \n",
       " 2010-01-07   24.218124  \n",
       " 2010-01-08   24.385145  \n",
       " 2010-01-11   24.074966  \n",
       " 2010-01-12   23.915895  \n",
       " 2010-01-13   24.138592  \n",
       " 2010-01-14   24.623755  \n",
       " 2010-01-15   24.544212  \n",
       " 2010-01-19   24.735104  \n",
       " 2010-01-20   24.329473  \n",
       " 2010-01-21   23.868181  \n",
       " 2010-01-22   23.033073  \n",
       " 2010-01-25   23.319397  \n",
       " 2010-01-26   23.462553  \n",
       " 2010-01-27   23.597769  \n",
       " 2010-01-28   23.192135  \n",
       " 2010-01-29   22.412704  \n",
       " 2010-02-01   22.595629  \n",
       " 2010-02-02   22.635405  \n",
       " 2010-02-03   22.770605  \n",
       " 2010-02-04   22.142290  \n",
       " 2010-02-05   22.285454  \n",
       " 2010-02-08   22.046848  \n",
       " 2010-02-09   22.277498  \n",
       " 2010-02-10   22.261591  \n",
       " 2010-02-11   22.364988  \n",
       " 2010-02-12   22.213871  \n",
       " 2010-02-16   22.653355  \n",
       " ...                ...  \n",
       " 2019-01-08  102.362839  \n",
       " 2019-01-09  103.826584  \n",
       " 2019-01-10  103.159431  \n",
       " 2019-01-11  102.362839  \n",
       " 2019-01-14  101.616028  \n",
       " 2019-01-15  104.563438  \n",
       " 2019-01-16  104.931862  \n",
       " 2019-01-17  105.668724  \n",
       " 2019-01-18  107.251953  \n",
       " 2019-01-22  105.230591  \n",
       " 2019-01-23  106.256210  \n",
       " 2019-01-24  105.748375  \n",
       " 2019-01-25  106.714249  \n",
       " 2019-01-28  104.633141  \n",
       " 2019-01-29  102.502243  \n",
       " 2019-01-30  105.927612  \n",
       " 2019-01-31  103.985909  \n",
       " 2019-02-01  102.342918  \n",
       " 2019-02-04  105.290337  \n",
       " 2019-02-05  106.764046  \n",
       " 2019-02-06  105.579102  \n",
       " 2019-02-07  104.822327  \n",
       " 2019-02-08  105.220634  \n",
       " 2019-02-11  104.802422  \n",
       " 2019-02-12  106.435448  \n",
       " 2019-02-13  106.355782  \n",
       " 2019-02-14  106.445404  \n",
       " 2019-02-15  107.759789  \n",
       " 2019-02-19  107.709999  \n",
       " 2019-02-20  107.150002  \n",
       " \n",
       " [2298 rows x 6 columns],\n",
       " 'GOOG':                    High          Low         Open        Close      Volume  \\\n",
       " Date                                                                         \n",
       " 2010-01-04   312.721039   310.103088   311.449310   311.349976   3937800.0   \n",
       " 2010-01-05   311.891449   308.761810   311.563568   309.978882   6048500.0   \n",
       " 2010-01-06   310.907837   301.220856   310.907837   302.164703   8009000.0   \n",
       " 2010-01-07   303.029083   294.410156   302.731018   295.130463  12912000.0   \n",
       " 2010-01-08   299.675903   292.651581   294.087250   299.064880   9509900.0   \n",
       " 2010-01-11   300.276978   295.100647   300.276978   298.612823  14519600.0   \n",
       " 2010-01-12   297.147339   292.100159   296.893982   293.332153   9769600.0   \n",
       " 2010-01-13   292.288940   285.095734   286.382355   291.648102  13077600.0   \n",
       " 2010-01-14   295.180145   289.521942   290.063416   293.019196   8535300.0   \n",
       " 2010-01-15   294.862213   287.152344   294.752930   288.126007  10939600.0   \n",
       " 2010-01-19   293.302338   286.283020   288.722137   291.911407   8689500.0   \n",
       " 2010-01-20   291.096710   285.786224   291.096710   288.329681   6543600.0   \n",
       " 2010-01-21   291.513977   284.276062   289.834900   289.606384  12697400.0   \n",
       " 2010-01-22   283.456390   265.701874   280.426086   273.227905  13689200.0   \n",
       " 2010-01-25   273.163330   266.024780   271.528961   268.255249   8897200.0   \n",
       " 2010-01-26   273.024231   266.412231   267.246826   269.457428   8767600.0   \n",
       " 2010-01-27   272.055542   265.925415   268.886169   269.298462   7980200.0   \n",
       " 2010-01-28   271.732635   263.585632   270.485748   265.418701   6500100.0   \n",
       " 2010-01-29   268.747070   261.106750   267.505127   263.257751   8334700.0   \n",
       " 2010-02-01   266.173798   263.436584   265.572693   264.787811   4530800.0   \n",
       " 2010-02-02   265.751556   262.100281   265.751556   263.843964   8245600.0   \n",
       " 2010-02-03   269.298462   262.408295   262.626862   268.662598   6037000.0   \n",
       " 2010-02-04   267.261719   261.081909   266.764954   261.687958   6799200.0   \n",
       " 2010-02-05   265.026245   259.541931   262.492737   263.928406   6353000.0   \n",
       " 2010-02-08   269.248810   264.047638   264.529480   265.011353   5423500.0   \n",
       " 2010-02-09   269.015320   265.806183   268.026733   266.486755   5675700.0   \n",
       " 2010-02-10   267.157410   262.140045   265.309418   265.498199   5383700.0   \n",
       " 2010-02-11   268.498688   263.039185   264.936829   266.466888   4851300.0   \n",
       " 2010-02-12   266.839478   263.535950   264.762970   264.837494   4589000.0   \n",
       " 2010-02-16   270.306915   265.423676   266.700378   268.901062   7356200.0   \n",
       " ...                 ...          ...          ...          ...         ...   \n",
       " 2019-01-08  1084.560059  1060.530029  1076.109985  1076.280029   1764900.0   \n",
       " 2019-01-09  1082.630005  1066.400024  1081.650024  1074.660034   1199300.0   \n",
       " 2019-01-10  1071.150024  1057.709961  1067.660034  1070.329956   1456400.0   \n",
       " 2019-01-11  1063.775024  1048.479980  1063.180054  1057.189941   1520800.0   \n",
       " 2019-01-14  1051.530029  1041.255005  1046.920044  1044.689941   1144300.0   \n",
       " 2019-01-15  1080.050049  1047.339966  1050.170044  1077.150024   1463600.0   \n",
       " 2019-01-16  1092.375000  1079.339966  1080.000000  1080.969971   1331800.0   \n",
       " 2019-01-17  1091.800049  1073.500000  1079.469971  1089.900024   1242700.0   \n",
       " 2019-01-18  1108.352051  1090.900024  1100.000000  1098.260010   1955600.0   \n",
       " 2019-01-22  1091.510010  1063.469971  1088.000000  1070.520020   1613500.0   \n",
       " 2019-01-23  1084.930054  1059.750000  1077.349976  1075.569946    967000.0   \n",
       " 2019-01-24  1079.474976  1060.699951  1076.479980  1073.900024   1361300.0   \n",
       " 2019-01-25  1094.000000  1081.819946  1085.000000  1090.989990   1119100.0   \n",
       " 2019-01-28  1083.000000  1063.800049  1080.109985  1070.079956   1284300.0   \n",
       " 2019-01-29  1075.150024  1055.864990  1072.680054  1060.619995   1021800.0   \n",
       " 2019-01-30  1091.000000  1066.849976  1068.430054  1089.060059   1279800.0   \n",
       " 2019-01-31  1117.329956  1095.410034  1103.000000  1116.369995   1538300.0   \n",
       " 2019-02-01  1125.000000  1104.890015  1112.400024  1110.750000   1462200.0   \n",
       " 2019-02-04  1132.800049  1109.020020  1112.660034  1132.800049   2576500.0   \n",
       " 2019-02-05  1146.849976  1117.248047  1124.839966  1145.989990   3552200.0   \n",
       " 2019-02-06  1147.000000  1112.770020  1139.569946  1115.229980   2105600.0   \n",
       " 2019-02-07  1104.839966  1086.000000  1104.160034  1098.709961   2044800.0   \n",
       " 2019-02-08  1098.910034  1086.550049  1087.000000  1095.060059   1075800.0   \n",
       " 2019-02-11  1105.944946  1092.859985  1096.949951  1095.010010   1065200.0   \n",
       " 2019-02-12  1125.295044  1105.849976  1106.800049  1121.369995   1609100.0   \n",
       " 2019-02-13  1134.729980  1118.500000  1124.989990  1120.160034   1049800.0   \n",
       " 2019-02-14  1128.229980  1110.444946  1118.050049  1121.670044    947600.0   \n",
       " 2019-02-15  1131.670044  1110.650024  1130.079956  1113.650024   1449800.0   \n",
       " 2019-02-19  1121.890015  1110.000000  1110.000000  1118.560059   1046400.0   \n",
       " 2019-02-20  1123.410034  1105.280029  1119.989990  1113.800049        51.0   \n",
       " \n",
       "               Adj Close  \n",
       " Date                     \n",
       " 2010-01-04   311.349976  \n",
       " 2010-01-05   309.978882  \n",
       " 2010-01-06   302.164703  \n",
       " 2010-01-07   295.130463  \n",
       " 2010-01-08   299.064880  \n",
       " 2010-01-11   298.612823  \n",
       " 2010-01-12   293.332153  \n",
       " 2010-01-13   291.648102  \n",
       " 2010-01-14   293.019196  \n",
       " 2010-01-15   288.126007  \n",
       " 2010-01-19   291.911407  \n",
       " 2010-01-20   288.329681  \n",
       " 2010-01-21   289.606384  \n",
       " 2010-01-22   273.227905  \n",
       " 2010-01-25   268.255249  \n",
       " 2010-01-26   269.457428  \n",
       " 2010-01-27   269.298462  \n",
       " 2010-01-28   265.418701  \n",
       " 2010-01-29   263.257751  \n",
       " 2010-02-01   264.787811  \n",
       " 2010-02-02   263.843964  \n",
       " 2010-02-03   268.662598  \n",
       " 2010-02-04   261.687958  \n",
       " 2010-02-05   263.928406  \n",
       " 2010-02-08   265.011353  \n",
       " 2010-02-09   266.486755  \n",
       " 2010-02-10   265.498199  \n",
       " 2010-02-11   266.466888  \n",
       " 2010-02-12   264.837494  \n",
       " 2010-02-16   268.901062  \n",
       " ...                 ...  \n",
       " 2019-01-08  1076.280029  \n",
       " 2019-01-09  1074.660034  \n",
       " 2019-01-10  1070.329956  \n",
       " 2019-01-11  1057.189941  \n",
       " 2019-01-14  1044.689941  \n",
       " 2019-01-15  1077.150024  \n",
       " 2019-01-16  1080.969971  \n",
       " 2019-01-17  1089.900024  \n",
       " 2019-01-18  1098.260010  \n",
       " 2019-01-22  1070.520020  \n",
       " 2019-01-23  1075.569946  \n",
       " 2019-01-24  1073.900024  \n",
       " 2019-01-25  1090.989990  \n",
       " 2019-01-28  1070.079956  \n",
       " 2019-01-29  1060.619995  \n",
       " 2019-01-30  1089.060059  \n",
       " 2019-01-31  1116.369995  \n",
       " 2019-02-01  1110.750000  \n",
       " 2019-02-04  1132.800049  \n",
       " 2019-02-05  1145.989990  \n",
       " 2019-02-06  1115.229980  \n",
       " 2019-02-07  1098.709961  \n",
       " 2019-02-08  1095.060059  \n",
       " 2019-02-11  1095.010010  \n",
       " 2019-02-12  1121.369995  \n",
       " 2019-02-13  1120.160034  \n",
       " 2019-02-14  1121.670044  \n",
       " 2019-02-15  1113.650024  \n",
       " 2019-02-19  1118.560059  \n",
       " 2019-02-20  1113.800049  \n",
       " \n",
       " [2298 rows x 6 columns]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas_datareader.data as web\n",
    "#all_data = {ticker: web.get_data_yahoo(ticker)\n",
    "#            for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']}\n",
    "import pickle\n",
    "all_data = pickle.load(open('all_data.pkl', 'rb'))\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.  Create two **DataFrames** for the price ('Adj Close') and volume ('Volume')\n",
    "2.  Compute the percent change in prices for the Google stock price (i.e. returns)\n",
    "3.  Use a one-liner to calculate the average of the total value of stocks traded during the period downloaded\n",
    "4.  Calculate the correlation (`corr` and `corrwith`) of the returns of the IBM and Microsoft stocks\n",
    "5.  Plot the volume of the IBM trades executed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IBM</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.48655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.48655</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IBM     MSFT\n",
       "IBM   1.00000  0.48655\n",
       "MSFT  0.48655  1.00000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = pd.DataFrame({ticker: all_data[ticker]['Adj Close'] for ticker in all_data})\n",
    "volume = pd.DataFrame({ticker: all_data[ticker]['Volume'] for ticker in all_data})\n",
    "returns = price.pct_change()\n",
    "returns[['IBM', 'MSFT']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading and writing data in text format\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although `read_csv` and `read_table` are the most commonly used, a number of other functions are available\n",
    "\n",
    "![img](images/parsing1.png)\n",
    "\n",
    "![img](images/parsing2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optional arguments for these functions fall into categories:\n",
    "\n",
    "-   Indexing\n",
    "-   Type inference and data conversion\n",
    "-   Datetime parsing\n",
    "-   Iterating\n",
    "-   Unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CSV files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('examples/ex1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('examples/ex1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if there's no header row?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('examples/ex2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "names = ['a', 'b', 'c', 'd', 'message']\n",
    "pd.read_csv('examples/ex2.csv', names=names, index_col='message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We can also form a hierarchical index from multiple columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/csv_mindex.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = pd.read_csv('examples/csv_mindex.csv', index_col=['key1', 'key2'])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What if the delimiter is non-standard?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_table('examples/ex3.txt', sep='\\s+')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('examples/ex4.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `na_values` option can take either a list or set of strings to consider missing\n",
    "values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('examples/ex4.csv', na_values=['NULL'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}\n",
    "pd.read_csv('examples/ex4.csv', na_values=sentinels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some read_csv/read_table function arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/parsing3.png)\n",
    "\n",
    "![img](images/parsing4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Write data to text format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('examples/ex4.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `to_csv` method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\*Look at the function's documentation and write the file \n",
    "\n",
    "-   using a different delimiter\n",
    "-   using the word MISSING for missing data\n",
    "-   with no header\n",
    "-   with only the first two columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## JSON data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON (short for JavaScript Object Notation) has become one of the standard formats\n",
    "for sending data by HTTP request between web browsers and other applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    "\"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    "\"pet\": null,\n",
    "\"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "{\"name\": \"Katie\", \"age\": 38,\n",
    "\"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Wes',\n",
       " 'places_lived': ['United States', 'Spain', 'Germany'],\n",
       " 'pet': None,\n",
       " 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zeus', 'Zuko']},\n",
       "  {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "result = json.loads(obj)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]}, {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we convert from JSON to a DataFrame?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "siblings\n",
    "json.dump(obj, open(\"example.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\n{\\\"name\\\": \\\"Wes\\\",\\n\\\"places_lived\\\": [\\\"United States\\\", \\\"Spain\\\", \\\"Germany\\\"],\\n\\\"pet\\\": null,\\n\\\"siblings\\\": [{\\\"name\\\": \\\"Scott\\\", \\\"age\\\": 30, \\\"pets\\\": [\\\"Zeus\\\", \\\"Zuko\\\"]},\\n{\\\"name\\\": \\\"Katie\\\", \\\"age\\\": 38,\\n\\\"pets\\\": [\\\"Sixes\\\", \\\"Stache\\\", \\\"Cisco\\\"]}]\\n}\\n\""
     ]
    }
   ],
   "source": [
    "!cat example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('example.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Install the `lxml`, `beautifulsoup4` and `html5lib` modules and familiarize yourself with their functionality.\n",
    "2.  The EPA uses the RatNet to monitor radiation in the air across the country. Download the data from [https://www.epa.gov/radnet/radnet-csv-file-downloads>](https://www.epa.gov/radnet/radnet-csv-file-downloads>)for Worcester, MA in 2018. \n",
    "    -   What was the maximum dose equivalent rate for 2018?\n",
    "    -   What was the average dose equivalent rate for the 20 largest gamma count rates? What is the standard deviation for the different channels?\n",
    "    -   Which gamma channel would be the best predictor for dose equivalent rate?\n",
    "    -   If 90 nSv/h were considered the safe threshold, how many days in 2018 were not safe?\n",
    "    -   Find the average and variance of the gamma count rates, when the dose rate was between 82 and 88 nSv/h.\n",
    "    -   Write a CSV file that has a column designating the dose rate as safe or unsafe.\n",
    "    -   Use an one-liner to calculate the range of values for each gamma count channel.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
